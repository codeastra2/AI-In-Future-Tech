{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch \nfrom torch.optim import Adam\n\nfrom transformers import DistilBertConfig,DistilBertTokenizer,DistilBertModel\nimport torch.nn as nn\nimport torch.nn.functional as F \nfrom torch.utils.data import Dataset, DataLoader\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfile_id_vs_txt = {}\ndataset_dict = {}\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        # print(os.path.join(dirname, filename))\n        if \".txt\" in filename:\n            file_id = filename[0:filename.find(\".txt\")]\n            file_id_vs_txt[file_id] = open(os.path.join(dirname, filename), 'r').read()\n        elif \".csv\" in  \"train.csv\":\n            dataset_dict[filename[0: filename.find(\".csv\")]] = pd.read_csv(os.path.join(dirname, filename))\n            \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-10T11:40:22.474430Z","iopub.execute_input":"2022-08-10T11:40:22.474835Z","iopub.status.idle":"2022-08-10T11:40:40.934537Z","shell.execute_reply.started":"2022-08-10T11:40:22.474802Z","shell.execute_reply":"2022-08-10T11:40:40.932825Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"texts_list = [file_id_vs_txt[row[1][\"essay_id\"]] for row in dataset_dict[\"train\"].iterrows()] \ndataset_dict[\"train\"][\"text\"] = texts_list\n\ntexts_list = [file_id_vs_txt[row[1][\"essay_id\"]] for row in dataset_dict[\"test\"].iterrows()] \ndataset_dict[\"test\"][\"text\"] = texts_list\n","metadata":{"execution":{"iopub.status.busy":"2022-08-10T11:41:01.927121Z","iopub.execute_input":"2022-08-10T11:41:01.927950Z","iopub.status.idle":"2022-08-10T11:41:03.881947Z","shell.execute_reply.started":"2022-08-10T11:41:01.927909Z","shell.execute_reply":"2022-08-10T11:41:03.880717Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"id_to_vec = {\n    \"Effective\": [0, 0 , 1],\n    \"Adequate\": [0, 1, 0],\n    \"Ineffective\": [1, 0, 0]\n}\n\nlabel_vecs_train = []\n\ndataset_dict[\"train\"][\"discourse_effectiveness_vec\"] = dataset_dict[\"train\"][\"discourse_effectiveness\"].map(id_to_vec)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-10T11:41:08.536394Z","iopub.execute_input":"2022-08-10T11:41:08.536810Z","iopub.status.idle":"2022-08-10T11:41:08.553291Z","shell.execute_reply.started":"2022-08-10T11:41:08.536775Z","shell.execute_reply":"2022-08-10T11:41:08.551873Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# dataset_dict[\"train\"]['discourse_effectiveness'].unique()\nprint(len(dataset_dict[\"train\"]))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T11:41:12.148596Z","iopub.execute_input":"2022-08-10T11:41:12.148999Z","iopub.status.idle":"2022-08-10T11:41:12.155098Z","shell.execute_reply.started":"2022-08-10T11:41:12.148958Z","shell.execute_reply":"2022-08-10T11:41:12.153956Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"36765\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2022-07-29T18:37:35.399506Z","iopub.execute_input":"2022-07-29T18:37:35.399935Z","iopub.status.idle":"2022-07-29T18:37:50.163113Z","shell.execute_reply.started":"2022-07-29T18:37:35.399853Z","shell.execute_reply":"2022-07-29T18:37:50.161632Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.12.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.8.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"\n\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\ndistilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n\nconfig = DistilBertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,dropout=0.1,num_labels=3,\n        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\nmax_seq_length = 120\n\nclass ClassifierModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.num_labels = config.num_labels\n\n        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n        self.pre_classifier = nn.Linear(config.hidden_size, config.hidden_size)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n        self.dropout = nn.Dropout(config.seq_classif_dropout)\n        self.softmax = nn.Softmax()\n        \n        nn.init.xavier_normal_(self.classifier.weight)\n\n    def forward(self, input_ids=None, attention_mask=None, head_mask=None, labels=None):\n        distilbert_output = self.distilbert(input_ids=input_ids,\n                                            attention_mask=attention_mask,\n                                            head_mask=head_mask)\n        hidden_state = distilbert_output[0]                    \n        pooled_output = hidden_state[:, 0]                   \n        pooled_output = self.pre_classifier(pooled_output)   \n        pooled_output = nn.ReLU()(pooled_output)             \n        pooled_output = self.dropout(pooled_output)        \n        \n        logits = self.classifier(pooled_output) \n        logits = self.softmax(logits)   \n        return logits\n\n        #nn.init.xavier_normal_(self.classifier.weight)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-10T11:41:33.856312Z","iopub.execute_input":"2022-08-10T11:41:33.856748Z","iopub.status.idle":"2022-08-10T11:41:54.198044Z","shell.execute_reply.started":"2022-08-10T11:41:33.856689Z","shell.execute_reply":"2022-08-10T11:41:54.197089Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eade49091e024f9aa500fa926467ab14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49eed23514994be9a262db8565e929ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a310791fe1ed4c2badd8891c8c45ea4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"263deffd1cde43589171657a30135940"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"class ClassifierDataset(Dataset):\n    def __init__(self, df, mode=\"train\"):\n        self.df = df\n        self.mode = mode\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        X = f\"{self.df.at[idx, 'text']} || {self.df.at[idx, 'discourse_text']} || {self.df.at[2, 'discourse_type']}\"\n        \n        tokenized_comment = tokenizer.tokenize(X)\n\n        if len(tokenized_comment) > max_seq_length:\n            tokenized_comment = tokenized_comment[:max_seq_length]\n\n        ids_review  = tokenizer.convert_tokens_to_ids(tokenized_comment)\n\n        padding = [0] * (max_seq_length - len(ids_review))\n\n        ids_review += padding\n\n        assert len(ids_review) == max_seq_length\n\n        #print(ids_review)\n        ids_review = torch.tensor(ids_review)\n        if self.mode == \"train\":\n            y = self.df.at[idx, \"discourse_effectiveness_vec\"] \n            \n            sample = {\n                \"X\": ids_review,\n                \"y\": torch.tensor(y).float()\n            }\n        else:\n            sample = {\n                \"X\": ids_review,\n                \"discourse_id\": self.df.at[idx, \"discourse_id\"]\n            }\n        \n        return sample\n\nmodel = ClassifierModel(config)\ntrain_dataset = ClassifierDataset(dataset_dict[\"train\"],mode=\"train\")\ntest_dataset = ClassifierDataset(dataset_dict[\"test\"], mode=\"test\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-10T11:43:24.486376Z","iopub.execute_input":"2022-08-10T11:43:24.486857Z","iopub.status.idle":"2022-08-10T11:43:25.549846Z","shell.execute_reply.started":"2022-08-10T11:43:24.486818Z","shell.execute_reply":"2022-08-10T11:43:25.548531Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"lr = 0.001\nnum_epochs = 20\noptimizer = Adam(model.parameters(), lr)\nloss = nn.CrossEntropyLoss() ","metadata":{"execution":{"iopub.status.busy":"2022-08-10T11:42:26.818010Z","iopub.execute_input":"2022-08-10T11:42:26.818804Z","iopub.status.idle":"2022-08-10T11:42:26.826588Z","shell.execute_reply.started":"2022-08-10T11:42:26.818760Z","shell.execute_reply":"2022-08-10T11:42:26.825667Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T11:42:30.951402Z","iopub.execute_input":"2022-08-10T11:42:30.952201Z","iopub.status.idle":"2022-08-10T11:42:30.963851Z","shell.execute_reply.started":"2022-08-10T11:42:30.952159Z","shell.execute_reply":"2022-08-10T11:42:30.962925Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"ClassifierModel(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n  (softmax): Softmax(dim=None)\n)"},"metadata":{}}]},{"cell_type":"code","source":"dataset_dict[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-10T11:42:36.720272Z","iopub.execute_input":"2022-08-10T11:42:36.720645Z","iopub.status.idle":"2022-08-10T11:42:36.760679Z","shell.execute_reply.started":"2022-08-10T11:42:36.720616Z","shell.execute_reply":"2022-08-10T11:42:36.759791Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"       discourse_id      essay_id  \\\n0      0013cc385424  007ACE74B050   \n1      9704a709b505  007ACE74B050   \n2      c22adee811b6  007ACE74B050   \n3      a10d361e54e4  007ACE74B050   \n4      db3e453ec4e2  007ACE74B050   \n...             ...           ...   \n36760  9f63b687e76a  FFA381E58FC6   \n36761  9d5bd7d86212  FFA381E58FC6   \n36762  f1b78becd573  FFA381E58FC6   \n36763  cc184624ca8e  FFA381E58FC6   \n36764  c8a973681feb  FFA381E58FC6   \n\n                                          discourse_text  \\\n0      Hi, i'm Isaac, i'm going to be writing about h...   \n1      On my perspective, I think that the face is a ...   \n2      I think that the face is a natural landform be...   \n3      If life was on Mars, we would know by now. The...   \n4      People thought that the face was formed by ali...   \n...                                                  ...   \n36760  For many people they don't like only asking on...   \n36761  also people have different views and opinions ...   \n36762  Advice is something that can impact a persons ...   \n36763  someone can use everything that many people sa...   \n36764  In conclusion asking for an opinion can be ben...   \n\n             discourse_type discourse_effectiveness  \\\n0                      Lead                Adequate   \n1                  Position                Adequate   \n2                     Claim                Adequate   \n3                  Evidence                Adequate   \n4              Counterclaim                Adequate   \n...                     ...                     ...   \n36760                 Claim                Adequate   \n36761                 Claim                Adequate   \n36762              Position                Adequate   \n36763              Evidence             Ineffective   \n36764  Concluding Statement             Ineffective   \n\n                                                    text  \\\n0      Hi, i'm Isaac, i'm going to be writing about h...   \n1      Hi, i'm Isaac, i'm going to be writing about h...   \n2      Hi, i'm Isaac, i'm going to be writing about h...   \n3      Hi, i'm Isaac, i'm going to be writing about h...   \n4      Hi, i'm Isaac, i'm going to be writing about h...   \n...                                                  ...   \n36760  Some people may ask multiple people for advice...   \n36761  Some people may ask multiple people for advice...   \n36762  Some people may ask multiple people for advice...   \n36763  Some people may ask multiple people for advice...   \n36764  Some people may ask multiple people for advice...   \n\n      discourse_effectiveness_vec  \n0                       [0, 1, 0]  \n1                       [0, 1, 0]  \n2                       [0, 1, 0]  \n3                       [0, 1, 0]  \n4                       [0, 1, 0]  \n...                           ...  \n36760                   [0, 1, 0]  \n36761                   [0, 1, 0]  \n36762                   [0, 1, 0]  \n36763                   [1, 0, 0]  \n36764                   [1, 0, 0]  \n\n[36765 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discourse_id</th>\n      <th>essay_id</th>\n      <th>discourse_text</th>\n      <th>discourse_type</th>\n      <th>discourse_effectiveness</th>\n      <th>text</th>\n      <th>discourse_effectiveness_vec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0013cc385424</td>\n      <td>007ACE74B050</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n      <td>Lead</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n      <td>[0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9704a709b505</td>\n      <td>007ACE74B050</td>\n      <td>On my perspective, I think that the face is a ...</td>\n      <td>Position</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n      <td>[0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c22adee811b6</td>\n      <td>007ACE74B050</td>\n      <td>I think that the face is a natural landform be...</td>\n      <td>Claim</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n      <td>[0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a10d361e54e4</td>\n      <td>007ACE74B050</td>\n      <td>If life was on Mars, we would know by now. The...</td>\n      <td>Evidence</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n      <td>[0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>db3e453ec4e2</td>\n      <td>007ACE74B050</td>\n      <td>People thought that the face was formed by ali...</td>\n      <td>Counterclaim</td>\n      <td>Adequate</td>\n      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n      <td>[0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36760</th>\n      <td>9f63b687e76a</td>\n      <td>FFA381E58FC6</td>\n      <td>For many people they don't like only asking on...</td>\n      <td>Claim</td>\n      <td>Adequate</td>\n      <td>Some people may ask multiple people for advice...</td>\n      <td>[0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>36761</th>\n      <td>9d5bd7d86212</td>\n      <td>FFA381E58FC6</td>\n      <td>also people have different views and opinions ...</td>\n      <td>Claim</td>\n      <td>Adequate</td>\n      <td>Some people may ask multiple people for advice...</td>\n      <td>[0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>36762</th>\n      <td>f1b78becd573</td>\n      <td>FFA381E58FC6</td>\n      <td>Advice is something that can impact a persons ...</td>\n      <td>Position</td>\n      <td>Adequate</td>\n      <td>Some people may ask multiple people for advice...</td>\n      <td>[0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>36763</th>\n      <td>cc184624ca8e</td>\n      <td>FFA381E58FC6</td>\n      <td>someone can use everything that many people sa...</td>\n      <td>Evidence</td>\n      <td>Ineffective</td>\n      <td>Some people may ask multiple people for advice...</td>\n      <td>[1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>36764</th>\n      <td>c8a973681feb</td>\n      <td>FFA381E58FC6</td>\n      <td>In conclusion asking for an opinion can be ben...</td>\n      <td>Concluding Statement</td>\n      <td>Ineffective</td>\n      <td>Some people may ask multiple people for advice...</td>\n      <td>[1, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n<p>36765 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\nops = model(input_ids=train_dataset[0][\"X\"][None, :].to(device))\n\ntrain_dataloader = DataLoader(train_dataset, 30, shuffle=True)\n\nfor epoch in range(num_epochs):\n    for bidx, sample in enumerate(train_dataloader):\n        with torch.set_grad_enabled(True):\n            y_hat = model(input_ids=sample[\"X\"].to(device))\n            y = sample[\"y\"].to(device)\n            optimizer.zero_grad()\n            crentr_loss = loss(y, y_hat)\n            crentr_loss.backward()\n            optimizer.step()\n\n            print(f\"Finished with batch idx {bidx},  {epoch} epochs\")\n    print(f\"Finished with {epoch} epochs\")\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-08-10T11:44:28.200491Z","iopub.execute_input":"2022-08-10T11:44:28.200898Z","iopub.status.idle":"2022-08-10T11:45:03.031123Z","shell.execute_reply.started":"2022-08-10T11:44:28.200864Z","shell.execute_reply":"2022-08-10T11:45:03.029239Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","output_type":"stream"},{"name":"stdout","text":"Finished with batch idx 0,  0 epochs\nFinished with batch idx 1,  0 epochs\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3173905420.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mcrentr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mcrentr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"op = model(input_ids=test_dataset[0][\"X\"][None, :])\ntest_dataloader = DataLoader(test_dataset, 64)\nresults_list = []\n\nfor sample in test_dataloader:\n    y_hat = model(input_ids=sample[\"X\"])\n    results_list.extend(y_hat.tolist())\n    \ntest_dataloader = DataLoader(test_dataset, 64)\nresults_list = []\n# print(len(test_dataset))\n\nfor sample in test_dataloader:\n    y_hat = model(input_ids=sample[\"X\"].to(device))\n    y_hat = y_hat.tolist()\n    for idx, lis in enumerate(y_hat):\n        lis.insert(0, sample[\"discourse_id\"][idx])\n    # print(y_hat)\n    results_list.extend(y_hat)\n\ndf = pd.DataFrame(results_list, columns=[\"discourse_id\" ,\"Ineffective\", \"Adequate\" ,\"Effective\"]) \ndf.to_csv(\"submission.csv\",  index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T11:47:22.000025Z","iopub.execute_input":"2022-08-10T11:47:22.001287Z","iopub.status.idle":"2022-08-10T11:47:24.309179Z","shell.execute_reply.started":"2022-08-10T11:47:22.001242Z","shell.execute_reply":"2022-08-10T11:47:24.308123Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","output_type":"stream"}]}]}